import gymnasium as gym
from stable_baselines3 import PPO
from PIL import Image

print("--- PHASE 1 : ENTRA√éNEMENT ---")
# Environnement sans rendu visuel pour acc√©l√©rer l'entra√Ænement au maximum
train_env = gym.make("LunarLander-v3")

# Initialisation du mod√®le PPO avec un r√©seau de neurones multicouches classique (MLP)
# verbose=1 permet d'afficher les logs d'entra√Ænement dans le terminal
model = PPO("MlpPolicy", train_env, verbose=1, device="cpu")

# Lancement de l'apprentissage (500 000 it√©rations sont un bon point de d√©part)
model.learn(total_timesteps=500000)

# Sauvegarde du mod√®le sur le disque
model.save("ppo_lunar_lander")
train_env.close()
print("Entra√Ænement termin√© et mod√®le sauvegard√© !")

print("\n--- PHASE 2 : √âVALUATION ET T√âL√âM√âTRIE ---")
# Nouvel environnement avec le mode de rendu pour extraire les images
eval_env = gym.make("LunarLander-v3", render_mode="rgb_array")

# Chargement du mod√®le (optionnel ici car il est d√©j√† en m√©moire, mais bonne pratique)
# model = PPO.load("ppo_lunar_lander")

obs, info = eval_env.reset()
done = False
frames = []

total_reward = 0.0
main_engine_uses = 0
side_engine_uses = 0

while not done:
    # L'agent PPO pr√©dit la meilleure action √† prendre. 
    # deterministic=True demande √† l'agent de prendre la meilleure action connue, sans explorer.
    action, _states = model.predict(obs, deterministic=True)
    
    # L'action choisie est envoy√©e √† l'environnement
    obs, reward, terminated, truncated, info = eval_env.step(action)
    
    # Mise √† jour des m√©triques
    total_reward += reward
    if action == 2:
        main_engine_uses += 1
    elif action in [1, 3]:
        side_engine_uses += 1
        
    # Capture de l'image
    frame = eval_env.render()
    frames.append(Image.fromarray(frame))
    
    done = terminated or truncated

eval_env.close()

# Analyse du vol
if reward == -100:
    issue = "CRASH D√âTECT√â üí•"
elif reward == 100:
    issue = "ATTERRISSAGE R√âUSSI üèÜ"
else:
    issue = "TEMPS √âCOUL√â OU SORTIE DE ZONE ‚ö†Ô∏è"

print("\n--- RAPPORT DE VOL PPO ---")
print(f"Issue du vol : {issue}")
print(f"R√©compense totale cumul√©e : {total_reward:.2f} points")
print(f"Allumages moteur principal : {main_engine_uses}")
print(f"Allumages moteurs lat√©raux : {side_engine_uses}")
print(f"Dur√©e du vol : {len(frames)} frames")

if frames:
    frames[0].save('trained_ppo_agent.gif', save_all=True, append_images=frames[1:], duration=30, loop=0)
    print("Vid√©o de la t√©l√©m√©trie sauvegard√©e sous 'trained_ppo_agent.gif'")
        